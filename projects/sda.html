<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Structured Domain Adaptation for Unsupervised Person Re-identification</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Unsupervised domain adaptation (UDA) aims at adapting the model trained on a labeled source-domain dataset to another target-domain dataset without any annotation. The task of UDA for the open-set person re-identification (re-ID) is even more challenging as the identities (classes) have no overlap between the two domains. Existing UDA methods for person re-ID have the following limitations. 1) Pseudo-label-based methods achieve state-of-the-art performances but ignore the complex relations between two domains' images, along with the valuable source-domain annotations. 2) Domain translation-based methods cannot achieve competitive performances as the domain translation is not properly regularized to generate informative enough training samples that well maintain inter-sample relations. To tackle the above challenges, we propose an end-to-end structured domain adaptation framework that consists of a novel structured domain-translation network and two domain-specific person image encoders. The structured domain-translation network can effectively transform the source-domain images into the target domain while well preserving the original intra- and inter-identity relations. The target-domain encoder could then be trained using both source-to-target translated images with valuable ground-truth labels and target-domain images with pseudo labels. Importantly, the domain-translation network and target-domain encoder are jointly optimized, improving each other towards the overall objective, i.e. to achieve optimal re-ID performances on the target domain. Our proposed framework outperforms state-of-the-art methods on multiple UDA tasks of person re-ID.">
<meta name="keywords" content="Structured Domain Translation; Unsupervised Domain Adaptation, Person Re-identification; Computer Vision; Deep Learning">
<link rel="author" href="https://yxgeee.github.io/">

<!-- Fonts and stuff -->
<link href="./files/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./files/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./files/iconize.css">
<script async="" src="./files/prettify.js"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">

      <div class="section head">
        <h1>Structured Domain Adaptation </h1>
        <h1>for Unsupervised Person Re-identification</h1>

	<div class="authors">
	  <a href="https://yxgeee.github.io/">Yixiao Ge</a><sup></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a href="http://home.ustc.edu.cn/~zhufengx/">Feng Zhu</a><sup></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://zhaorui.xyz/">Rui Zhao</a><sup></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a><sup></sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, The Chinese University of Hong Kong</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<!-- <div class="venue">International Conference on Learning Representations (<a href="https://iclr.cc/" target="_blank">ICLR</a>) 2020 </div> -->

    </div>

    <center><img src="./sda/intro.png" border="0" width="80%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
Unsupervised domain adaptation (UDA) aims at adapting the model trained on a labeled source-domain dataset to another target-domain dataset without any annotation. The task of UDA for the open-set person re-identification (re-ID) is even more challenging as the identities (classes) have no overlap between the two domains. Existing UDA methods for person re-ID have the following limitations. 1) Pseudo-label-based methods achieve state-of-the-art performances but ignore the complex relations between two domains' images, along with the valuable source-domain annotations. 2) Domain translation-based methods cannot achieve competitive performances as the domain translation is not properly regularized to generate informative enough training samples that well maintain inter-sample relations. To tackle the above challenges, we propose an end-to-end structured domain adaptation framework that consists of a novel structured domain-translation network and two domain-specific person image encoders. The structured domain-translation network can effectively transform the source-domain images into the target domain while well preserving the original intra- and inter-identity relations. The target-domain encoder could then be trained using both source-to-target translated images with valuable ground-truth labels and target-domain images with pseudo labels. Importantly, the domain-translation network and target-domain encoder are jointly optimized, improving each other towards the overall objective, i.e. to achieve optimal re-ID performances on the target domain. Our proposed framework outperforms state-of-the-art methods on multiple UDA tasks of person re-ID.
	</p>
      </div>

<!-- <div class="section demo">
	<h2>Public Video</h2>
	<br>
	<center>
	  <iframe width="810" height="480" src="https://www.youtube.com/embed/YcmgCCRA1qc" frameborder="0" allowfullscreen></iframe>
  </video>
	    </center>
      <center>
      <a href="https://www.bilibili.com/video/BV1JT4y157Wt">Alternatively watch in bilibili</a>
      </center>
	    </div>

<br> -->

<div class="section materials">
	<h2>Materials</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://arxiv.org/abs/2003.06650" target="_blank" class="imageLink"><img src="./files/arxiv.png"></a><br>
		  <a href="https://arxiv.org/abs/2003.06650" target="_blank">Paper</a>
		</div>
	      </li>

        <!-- <li class="grid">
        <div class="griditem">
        <a href="../files/MMT-ICLR20.pdf" target="_blank" class="imageLink"><img src="./mmt/slides.jpg"></a><br>
        <a href="../files/MMT-ICLR20.pdf" target="_blank">Slides</a>
        </div>
        </li> -->

        <li class="grid">
      <div class="griditem">
  <a href="https://github.com/yxgeee/" target="_blank" class="imageLink"><img src="./files/code.png"></a><br>
    <a href="https://github.com/yxgeee/" target="_blank">Code and Models (Coming Soon)</a>
  </div>
      </li>

	    </ul>
	    </center>
	    </div>

<br>

<!-- <div class="section presentation">
	<h2>Presentation</h2>
	<center>
	  <ul> -->
            <!-- <li class="grid">
	      <div class="griditem">
		<a href="https://www.youtube.com/watch?v=BQZ5xKd5kis&t=1361" target="_blank" class="imageLink"><img src="./compounddomain/video.png"></a><br>
		  <a href="https://www.youtube.com/watch?v=BQZ5xKd5kis&t=1361" target="_blank">Video Recording</a>
		</div>
	      </li> -->


	    <!-- </ul>
	    </center>
	    </div>

<br> -->

<!-- <div class="section code">
	<h2>Code and Models</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://github.com/yxgeee/MMT" target="_blank" class="imageLink"><img src="./mmt/code.png"></a><br>
		  <a href="https://github.com/yxgeee/MMT" target="_blank">Code and Models</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>

<br> -->

<!-- <div class="section data">
	<h2>Datasets</h2>
	<br>
	<center>
      	<a href="https://drive.google.com/open?id=1j7Nkfe6ZhzKFXePHdsseeeGI877Xu1yf" target="_blank" class="imageLink"><img src="./compounddomain/dataset.png" border="2" width="70%"></a><br>
      	<a href="https://drive.google.com/open?id=1j7Nkfe6ZhzKFXePHdsseeeGI877Xu1yf" target="_blank">Open Long-Tailed Datasets</a>
    </center>
    </div>

<br>-->

<!-- <div class="section blog">
	<h2>Blog</h2>
	<center>
	  <ul>

          <li class="grid">
	      <div class="griditem">
		<a href="https://zhuanlan.zhihu.com/p/116074945" target="_blank" class="imageLink"><img src="./files/Zhihu_logo.png"></a><br>
		  <a href="https://zhuanlan.zhihu.com/p/116074945" target="_blank">Zhihu Blog (in Chinese)</a>
		</div>
	      </li>

	    </ul>
	    </center>
	    </div>

<br> -->

<div class="section citation">
	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@article{ge2020structured,
  title={Structured Domain Adaptation for Unsupervised Person Re-identification},
  author={Ge, Yixiao and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2003.06650},
  year={2020}
}</pre>
	  </div>
      </div>

</body></html>
