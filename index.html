<!DOCTYPE html>
<html lang="en">
<head>
	<title>Yixiao Ge</title>

	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="Xiaoying Riley at 3rd Wave Media">
	<link rel="shortcut icon" href="images/favicon.ico">

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">

	<!-- FontAwesome JS-->
	<script defer src="assets/fontawesome/js/all.min.js"></script>

	<!-- Theme CSS -->
	<link id="theme-style" rel="stylesheet" href="assets/css/devresume.css">

</head>

<body>
	<!-- DEMO ONLY -->
	<div class="main-wrapper">
		<div class="container px-3 px-lg-5">
			<article class="resume-wrapper mx-auto theme-bg-light p-5 mb-5 my-5 shadow-lg">

				<div class="resume-header">
					<div class="row align-items-center">
						<div class="resume-title col-12 col-md-6 col-lg-8 col-xl-9">
							<h1><font face="verdana">Yixiao Ge</font></h1>
							<!-- <div class="resume-tagline mb-3 mb-md-0">Researcher @ Tencent ARC Lab & Tencent AI Lab</div> -->
						</div><!--//resume-title-->
						<div class="resume-contact col-12 col-md-6 col-lg-4 col-xl-3">
							<ul class="list-unstyled mb-0">
								<li class="mb-2"><i class="fas fa-envelope-square fa-fw fa-lg mr-2"></i><a class="resume-link" href="mailto:geyixiao831@gmail.com">geyixiao831@gmail.com</a></li>
								<li class="mb-2"><i class="fab fa-google fa-fw fa-lg mr-2"></i><a class="resume-link" href="https://scholar.google.com/citations?user=TtU74NAAAAAJ&hl=en">Google Scholar</a></li>
								<li class="mb-2"><i class="fas fab fa-github fa-fw fa-lg mr-2 "></i><a class="resume-link" href="https://github.com/yxgeee">Github</a></li>
								<li class="mb-0"><i class="fas fa-map-marker-alt fa-fw fa-lg mr-2"></i>Beijing, China</li>
							</ul>
						</div><!--//resume-contact-->
					</div><!--//row-->

				</div><!--//resume-header-->
				<hr>
				<div class="resume-intro py-3">
					<div class="media flex-column flex-md-row align-items-center">
						<img class="resume-profile-image mb-3 mb-md-0 mr-md-5 ml-md-0 rounded mx-auto" src="images/yxge_2021.jpg" alt="image">
						<div class="media-body text-left">
							<p class="mb-0">
								I am currently a senior researcher at <a href="https://arc.tencent.com/en/index" target="_blank">Tencent ARC Lab</a> and <a href="https://ai.tencent.com/ailab/en/index" target="_blank">Tencent AI Lab</a>, leading an effort on <b>vision and multimodal foundation models</b> with a particular interest in <b>generative comprehension</b>.
				                Previously, I got my Ph.D. degree from <a href="http://mmlab.ie.cuhk.edu.hk/" target="_blank">Multimedia Lab (MMLab)</a>, <a href="http://www.cuhk.edu.hk/english/index.html" target="_blank">the Chinese University of Hong Kong</a>,
				                advised by <a href="http://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Prof. Hongsheng Li</a> and <a href="http://www.ee.cuhk.edu.hk/~xgwang/" target="_blank">Prof. Xiaogang Wang</a>.
				                <!-- Previously, I received the B.Eng. degree from <a href="http://english.hust.edu.cn/" target="_blank">Huazhong University of Science and Technology</a>. -->
				                 <!-- in 2017. -->
				                <!-- My research interests include computer vision and deep learning with focus on foundation models and vision+language. -->
				                <!-- large-scale pre-training, un/self-/semi-/weakly-supervised learning, image/video/cross-modality representation learning, transfer learning, etc. -->
								<!-- <font color="#3366CC">[<a href="https://scholar.google.com/citations?user=TtU74NAAAAAJ&hl=en">Google Scholar</a>]</font> -->
								<!-- <br> -->
								<font color="#CC0033">We are actively looking for research interns to work on related research topics, including but not limited to large-scale pretraining, vision and language. Please feel free to reach out if you are interested.</font>
							</p>
						</div><!--//media-body-->
					</div>
				</div><!--//resume-intro-->
				<hr>
				<div class="resume-body">
					<div class="row">
						<div class="resume-main col-12 col-lg-8 col-xl-9 pr-0 pr-lg-5">
							<section class="work-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">News</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list" style="list-style: outside;list-style-type: square;">
											<li> <b>[Apr 2023]</b> One paper is accepted to ICML 2023.</li>
											<li> <b>[Apr 2023]</b> We release several interesting projects towards generative comprehension: <font color="#CC0033">TagGPT, Caption Anything, VLog, and GPT4Tools</font>. Welcome to check them out!</li>
											<li> <b>[Feb 2023]</b> Four papers are accepted to CVPR 2023.</li>
											<li> <b>[Jan 2023]</b> One paper is accepted to ICLR 2023.</li>
											<li> <b>[Nov 2022]</b> Two papers are accepted to AAAI 2023.</li>
											<li> <b>[Jul 2022]</b> Three papers are accepted to ECCV 2022.</li>
											<li> <b>[Apr 2022]</b> One paper is accepted to IJCAI 2022 as a <font color="#CC0033">Long oral</font> presentation.</li>
											<li> <b>[Mar 2022]</b> Two papers are accepted to CVPR 2022 with one <font color="#CC0033">Oral</font> presentation.</li>
											<li> <b>[Jan 2022]</b> Three papers are accepted to ICLR 2022.</li>
											<!-- <li> <b>[Jul 2021]</b> Two papers are accepted to ICCV 2021.</li> -->
											<!-- <li> <b>[Mar 2021]</b> Three papers are accepted to CVPR 2021.</li> -->
											<!-- <li> <b>[Sep 2020]</b> One paper is accepted to NeurIPS 2020.</li> -->
											<!-- <li> <b>[Aug 2020]</b> We achieved 2nd place in <a href='http://ai.bu.edu/visda-2020/'>VisDA-2020 Challenge</a> in ECCV 2020. <a href='https://geyixiao.com/projects/visda.html'>[Project]</a> </li> -->
												<!-- <a href='https://arxiv.org/abs/2008.10313'>[pdf]</a> <a href='https://github.com/yxgeee/MMT-plus'>[code]</a></li> -->
											<!-- <li> <b>[Jul 2020]</b> One paper is accepted to ECCV 2020 as a <font color="#CC0033">Spotlight</font> presentation.</li> -->
											<!-- <li><b>[Jul 2020]</b> The OpenUnReID codebase is online. <a href='https://github.com/open-mmlab/OpenUnReID'>[Code]</a></li> -->
											<!-- <li> <b>[Dec 2019]</b> One paper is accepted to ICLR 2020.</li>
											<li> <b>[Sep 2018]</b> One paper is accepted to NeurIPS 2018.</li> -->
										</ul>
									</div>
								</div><!--//item-->


							</section><!--//work-section-->

							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Projects</h3>
								<div class="item mb-3">
									<div class="item-content">

									<font color="#39AB56">
										<b>Welcome to check out our interesting projects
										</b>
									</font>
									<br>
									<br>

									<font color="#39AB56"><b>2023:</b></font>
									<ul class="resume-list" style="list-style: outside;" >
									<li>
										<div class="resume-degree font-weight-bold">
											GPT4Tools: Teaching LLM to Use Tools via Self-instruction
										</div>
										<font color="#CC0033">
											We for the first time enable Vicuna-13B to use visual models via self-instruct tuning. The system can be deployed on local machines without APIs.
										</font>
										<div class="resume-degree-org text-muted">
											Lin Song, Yanwei Li, Rui Yang, Sijie Zhao, <b>Yixiao Ge</b>, Ying Shan
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://gpt4tools.github.io/" target="_blank">Project</a>]
											[<a href = "https://www.youtube.com/watch?v=Qrj94ibQIT8" target="_blank">Demo Video</a>]
											[<a href = "https://github.com/StevenGrove/GPT4Tools" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/StevenGrove/GPT4Tools?style=social">
										</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">
											VLog: Video as a Long Document
										</div>
										<font color="#CC0033">
											Given a long video, we turn it into a document containing visual + audio info. By sending this document to ChatGPT, we can chat over the video!
										</font>
										<div class="resume-degree-org text-muted">
											[<a href = "https://huggingface.co/spaces/TencentARC/VLog" target="_blank">Demo</a>]
											[<a href = "https://github.com/showlab/VLog" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/showlab/VLog?style=social">
										</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">
											Caption Anything: Interactive Image Description with Diverse Multimodal Controls
										</div>
										<font color="#CC0033">
											We generate descriptive captions for any object within an image, offering a range of language styles to accommodate diverse user preferences. It supports visual controls (mouse click) and language controls (length, sentiment, factuality, and language).
										</font>
										<div class="resume-degree-org text-muted">
											Teng Wang*, Jinrui Zhang*, Junjie Fei*, <b>Yixiao Ge</b>, Hao Zheng, Yunlong Tang, Zhe Li, Mingqi Gao, Shanshan Zhao, Ying Shan, Feng Zheng
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://arxiv.org/abs/2305.02677" target="_blank">Tech Report</a>]
											[<a href = "https://huggingface.co/spaces/TencentARC/Caption-Anything" target="_blank">Demo</a>]
											[<a href = "https://github.com/ttengwang/Caption-Anything" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/ttengwang/Caption-Anything?style=social">
										</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">
											TagGPT: Large Language Models are Zero-shot Multimodal Taggers
										</div>
										<font color="#CC0033">
											TagGPT is a fully automated system capable of tag extraction and multimodal tagging in a completely zero-shot fashion.
										</font>
										<div class="resume-degree-org text-muted">
											Chen Li, <b>Yixiao Ge</b>, Jiayong Mao, Dian Li, Ying Shan
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://arxiv.org/abs/2304.03022" target="_blank">Tech Report</a>]
											[<a href = "https://huggingface.co/spaces/TencentARC/TagGPT" target="_blank">Demo</a>]
											[<a href = "https://github.com/TencentARC/TagGPT" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/TagGPT?style=social">
										</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">
											Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation
										</div>
										<font color="#CC0033">
											Given a video-text pair as input, our method, Tune-A-Video, fine-tunes a pre-trained text-to-image diffusion model for text-to-video generation.
										</font>
										<div class="resume-degree-org text-muted">
											Jay Zhangjie Wu, <b>Yixiao Ge</b>, Xintao Wang, Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, Mike Zheng Shou
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://tuneavideo.github.io/" target="_blank">Project</a>]
											[<a href = "https://arxiv.org/abs/2212.11565" target="_blank">Tech Report</a>]
											[<a href = "https://huggingface.co/spaces/Tune-A-Video-library/Tune-A-Video-inference" target="_blank">Demo</a>]
											[<a href = "https://github.com/showlab/Tune-A-Video" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/showlab/Tune-A-Video?style=social">
										</div>
									</li>

								</ul>

									<font color="#39AB56"><b>Before 2023:</b></font>
									<ul class="resume-list" style="list-style: outside;" >
									<li>
										<div class="resume-degree font-weight-bold">
											OpenIBL: PyTorch-based Codebase for Image Localization
										</div>
										<div class="resume-degree-org text-muted">
											<b>Yixiao Ge</b>
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://github.com/yxgeee/OpenIBL" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/OpenIBL?style=social">
										</div>
									</li>
									<li>
										<div class="resume-degree font-weight-bold">
											OpenUnReID: PyTorch-based Codebase for Object Re-ID
										</div>
										<div class="resume-degree-org text-muted">
											<b>Yixiao Ge</b>, Tong Xiao, Zhiwei Zhang
										</div>
										<div class="resume-degree-org text-muted">
											[<a href = "https://github.com/open-mmlab/OpenUnReID" target="_blank">Code</a>]
											<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/open-mmlab/OpenUnReID?style=social">
										</div>
									</li>
								</ul>
								</div>
							</div>
							</section>

							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Publications <a href='https://scholar.google.com/citations?user=TtU74NAAAAAJ&hl=en'>[Full List]</a></h3>

								<div class="item mb-3">
									<div class="item-content">
										<!-- <font color="#39AB56"><b>Selected Preprints:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

										</ul> -->
										<font color="#39AB56">
											<b>(&nbsp;*equal contribution &nbsp; <sup>#</sup>corresponding author&nbsp;)
											<!-- <sup><span lang="EN-US" style="mso-bidi-font-size:8pt;font-family:Wingdings;mso-ascii-font-family:'Times New Roman';mso-hansi-font-family:'Times New Roman';mso-char-type:symbol;mso-symbol-font-family:Wingdings">*</span></sup>corresponding author) -->
											</b>
										</font>
										<br>
										<br>

										<!-- <font color="#39AB56"><b>Selected Preprints:</b></font>
										<ul class="resume-list" style="list-style: outside;" >


											<li>
												<div class="resume-degree font-weight-bold">
													Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection
												</div>
												<div class="resume-degree-org text-muted">
													Yuxin Fang*, Shusheng Yang*, Shijie Wang*, <b>Yixiao Ge</b>, Ying Shan, Xinggang Wang
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Tech report, 2022</font>
													[<a href = "https://arxiv.org/abs/2204.02964" target="_blank">Paper</a>]
													[<a href = "https://github.com/hustvl/MIMDet" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/hustvl/MIMDet?style=social">
												</div>
											</li> -->

											<!-- <li>
												<div class="resume-degree font-weight-bold">
													Revitalize Region Feature for Democratizing Video-Language Pre-training
												</div>
												<div class="resume-degree-org text-muted">
													Guanyu Cai, <b>Yixiao Ge</b>, Alex Jinpeng Wang, Rui Yan, Xudong Lin, Ying Shan, Lianghua He, Xiaohu Qie, Jianping Wu, Mike Zheng Shou
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Tech report, 2022</font>
													[<a href = "https://arxiv.org/abs/2203.07720" target="_blank">Paper</a>]
													[<a href = "https://github.com/CuthbertCai/DemoVLP" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/CuthbertCai/DemoVLP?style=social">
												</div>
											</li> -->

											<!-- <li>
												<div class="resume-degree font-weight-bold">
													Privacy-Preserving Model Upgrades with Bidirectional Compatible Training in Image Retrieval
												</div>
												<div class="resume-degree-org text-muted">
													Shupeng Su*, Binjie Zhang*, <b>Yixiao Ge<sup>#</sup></b>, Xuyuan Xu, Yexin Wang, Chun Yuan, Ying Shan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Tech report, 2022</font>
													[<a href = "https://arxiv.org/abs/2204.13919" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/OpenCompatible" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/OpenCompatible?style=social">
												</div>
											</li> -->


											<!-- <li>
												<div class="resume-degree font-weight-bold">
													Self-distillation with Batch Knowledge Ensembling Improves ImageNet Classification
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge</b>, Xiao Zhang, Ching Lam Choi, Ka Chun Cheung, Peipei Zhao, Feng Zhu, Xiaogang Wang, Rui Zhao, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">Tech report, 2021</font>
													[<a href = "./projects/bake.html" target="_blank">Project</a>]
													[<a href = "https://arxiv.org/abs/2104.13298" target="_blank">Paper</a>]
													[<a href = "https://github.com/yxgeee/BAKE" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/BAKE?style=social">
												</div>
											</li>
										</ul> -->

										<font color="#39AB56"><b>2023:</b></font>
										<ul class="resume-list" style="list-style: outside;" >
											<li>
												<div class="resume-degree font-weight-bold">
													π-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation
												</div>
												<div class="resume-degree-org text-muted">
													Chengyue Wu, Teng Wang, <b>Yixiao Ge<sup>#</sup></b>, Zeyu Lu, Ruisong Zhou, Ying Shan, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICML, 2023</font>
													[<a href = "https://arxiv.org/abs/2304.14381" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/pi-Tuning" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/pi-Tuning?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Accelerating Vision-Language Pretraining with Free Language Modeling
												</div>
												<div class="resume-degree-org text-muted">
													Teng Wang, <b>Yixiao Ge</b>, Feng Zheng, Ran Cheng, Ying Shan, Xiaohu Qie, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2023</font>
													[<a href = "https://arxiv.org/abs/2303.14038" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/FLM" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/FLM?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Masked Visual Reconstruction in Language Semantic Space
												</div>
												<div class="resume-degree-org text-muted">
													Shusheng Yang, <b>Yixiao Ge<sup>#</sup></b>, Kun Yi, Dian Li, Ying Shan, Xiaohu Qie, Xinggang Wang<sup>#</sup>
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2023</font>
													[<a href = "https://arxiv.org/abs/2301.06958" target="_blank">Paper</a>]
													[<a href = "https://github.com/hustvl/RILS" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/hustvl/RILS?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Learning Transferable Spatiotemporal Representations from Natural Script Knowledge
												</div>
												<div class="resume-degree-org text-muted">
													Ziyun Zeng*, Yuying Ge*, Xihui Liu, Bin Chen<sup>#</sup>, Ping Luo, Shu-Tao Xia, <b>Yixiao Ge<sup>#</sup></b>
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2023</font>
													[<a href = "https://arxiv.org/abs/2209.15280" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/TVTS" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/TVTS?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													All in One: Exploring Unified Video-Language Pre-training
												</div>
												<div class="resume-degree-org text-muted">
													Alex Jinpeng Wang, <b>Yixiao Ge</b>, Rui Yan, Yuying Ge, Xudong Lin, Guanyu Cai, Jianping Wu, Ying Shan, Xiaohu Qie, Mike Zheng Shou
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2023</font>
													[<a href = "https://arxiv.org/abs/2203.07303" target="_blank">Paper</a>]
													[<a href = "https://github.com/showlab/all-in-one" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/showlab/all-in-one?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Masked Image Modeling with Denoising Contrast
												</div>
												<div class="resume-degree-org text-muted">
													Kun Yi*, <b>Yixiao Ge*<sup>#</sup></b>, Xiaotong Li, Shusheng Yang, Dian Li, Jianping Wu, Ying Shan, Xiaohu Qie
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICLR, 2023</font>
													[<a href = "https://openreview.net/pdf?id=1fZd4owfJP6" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/ConMIM" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/ConMIM?style=social">
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Darwinian Model Upgrades: Model Evolving with Selective Compatibility
												</div>
												<div class="resume-degree-org text-muted">
													Binjie Zhang*, Shupeng Su*, <b>Yixiao Ge<sup>#</sup></b>, Xuyuan Xu, Yexin Wang, Chun Yuan, Mike Zheng Shou, Ying Shan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">AAAI, 2023</font>
													[<a href = "https://arxiv.org/abs/2210.06954" target="_blank">Paper</a>]
													<!-- [<a href = "https://arxiv.org/abs/2204.13919" target="_blank">Paper (v1)</a>] -->
													<!-- [<a href = "https://github.com/TencentARC/OpenCompatible" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/OpenCompatible?style=social"> -->
												</div>
											</li>
											<li>
												<div class="resume-degree font-weight-bold">
													Video-Text Pre-training with Learned Regions
												</div>
												<div class="resume-degree-org text-muted">
													Rui Yan, Mike Zheng Shou, <b>Yixiao Ge</b>, Alex Jinpeng Wang, Xudong Lin, Guanyu Cai, Jinhui Tang
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">AAAI, 2023</font>
													[<a href = "https://arxiv.org/abs/2112.01194" target="_blank">Paper</a>]
													[<a href = "https://github.com/showlab/Region_Learner" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/showlab/Region_Learner?style=social">
												</div>
											</li>
										</ul>

										<font color="#39AB56"><b>2022:</b></font>
										<ul class="resume-list" style="list-style: outside;" >


											<li>
												<div class="resume-degree font-weight-bold">
													MILES: Visual BERT Pre-training with Injected Language Semantics for Video-text Retrieval
												</div>
												<div class="resume-degree-org text-muted">
													Yuying Ge, <b>Yixiao Ge</b>, Xihui Liu, Jinpeng Wang, Jianping Wu, Ying Shan, Xiaohu Qie, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ECCV, 2022</font>
													[<a href = "https://arxiv.org/abs/2204.12408" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/MCQ/tree/main/MILES" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/MCQ?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space
												</div>
												<div class="resume-degree-org text-muted">
													Wenqi Shao<sup>#</sup>, Xun Zhao, <b>Yixiao Ge<sup>#</sup></b>, Zhaoyang Zhang, Lei Yang, Xiaogang Wang, Ying Shan, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ECCV, 2022</font>
													[<a href = "https://arxiv.org/abs/2207.03036" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/SFDA" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/SFDA?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													mc-BEiT: Multi-choice Discretization for Image BERT Pre-training
												</div>
												<div class="resume-degree-org text-muted">
													Xiaotong Li, <b>Yixiao Ge</b>, Kun Yi, Zixuan Hu, Ying Shan, Lingyu Duan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ECCV, 2022</font>
													[<a href = "https://arxiv.org/abs/2203.15371" target="_blank">Paper</a>]
													[<a href = "https://github.com/lixiaotong97/mc-BEiT" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/lixiaotong97/mc-BEiT?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Towards Universal Backward-Compatible Representation Learning
												</div>
												<div class="resume-degree-org text-muted">
													Binjie Zhang, <b>Yixiao Ge<sup>#</sup></b>, Yantao Shen, Shupeng Su, Fanzi Wu, Chun Yuan<sup>#</sup>, Xuyuan Xu, Yexin Wang, Ying Shan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">IJCAI, 2022 <b>(Long oral)</b></font>
													<!-- [<a href = "https://geyuying.github.io/MCQ.html" target="_blank">Project</a>] -->
													[<a href = "https://arxiv.org/abs/2203.01583" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/OpenCompatible" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/OpenCompatible?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Bridging Video-text Retrieval with Multiple Choice Questions
												</div>
												<div class="resume-degree-org text-muted">
													Yuying Ge, <b>Yixiao Ge</b>, Xihui Liu, Dian Li, Ying Shan, Xiaohu Qie, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2022 <b>(Oral)</b></font>
													<!-- [<a href = "https://geyuying.github.io/MCQ.html" target="_blank">Project</a>] -->
													[<a href = "https://arxiv.org/abs/2201.04850" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/MCQ" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/MCQ?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Object-aware Video-language Pre-training for Retrieval
												</div>
												<div class="resume-degree-org text-muted">
													Alex Jinpeng Wang, <b>Yixiao Ge</b>, Guanyu Cai, Rui Yan, Xudong Lin, Ying Shan, Xiaohu Qie, Mike Zheng Shou
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2022</font>
													<!-- [<a href = "./projects/bake.html" target="_blank">Project</a>] -->
													[<a href = "https://arxiv.org/abs/2112.00656" target="_blank">Paper</a>]
													[<a href = "https://github.com/FingerRec/OA-Transformer" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/FingerRec/OA-Transformer?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Hot-Refresh Model Upgrades with Regression-Alleviating Compatible Training in Image Retrieval
												</div>
												<div class="resume-degree-org text-muted">
													Binjie Zhang, <b>Yixiao Ge<sup>#</sup></b>, Yantao Shen, Yu Li, Chun Yuan<sup>#</sup>, Xuyuan Xu, Yexin Wang, Ying Shan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICLR, 2022</font>
													<!-- [<a href = "./projects/bake.html" target="_blank">Project</a>] -->
													[<a href = "https://openreview.net/pdf?id=HTp-6yLGGX" target="_blank">Paper</a>]
													[<a href = "https://github.com/TencentARC/OpenCompatible" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/TencentARC/OpenCompatible?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Dynamic Token Normalization Improves Vision Transformer
												</div>
												<div class="resume-degree-org text-muted">
													Wenqi Shao, <b>Yixiao Ge</b>, Zhaoyang Zhang, Xuyuan Xu, Xiaogang Wang, Ying Shan, Ping Luo
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICLR, 2022</font>
													<!-- [<a href = "./projects/bake.html" target="_blank">Project</a>] -->
													[<a href = "https://openreview.net/pdf?id=f9MHpAGUyMn" target="_blank">Paper</a>]
													[<a href = "https://github.com/wqshao126/DTN" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/wqshao126/DTN?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Uncertainty Modeling for Out-of-Distribution Generalization
												</div>
												<div class="resume-degree-org text-muted">
													Xiaotong Li, Yongxing Dai, <b>Yixiao Ge</b>, Jun Liu, Ying Shan, Lingyu Duan
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICLR, 2022</font>
													<!-- [<a href = "./projects/bake.html" target="_blank">Project</a>] -->
													[<a href = "https://openreview.net/pdf?id=6HN7LHyzGgC" target="_blank">Paper</a>]
													[<a href = "https://github.com/lixiaotong97/DSU" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/lixiaotong97/DSU?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Structured Domain Adaptation with Online Relation Regularization for Unsupervised Person Re-ID
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge</b>, Feng Zhu, Dapeng Chen, Rui Zhao, Xiaogang Wang, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">IEEE TNNLS, 2022</font>
													[<a href = "./projects/sda.html" target="_blank">Project</a>]
													[<a href = "https://arxiv.org/abs/2003.06650" target="_blank">Paper</a>]
													<!-- [<a href = "https://github.com/yxgeee/SDA" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/SDA?style=social"> -->
												</div>
											</li>

										</ul>

										<font color="#39AB56"><b>2021:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

											<li>
												<div class="resume-degree font-weight-bold">
													Progressive Correspondence Pruning by Consensus Learning
												</div>
												<div class="resume-degree-org text-muted">
													Chen Zhao*, <b>Yixiao Ge*</b>, Feng Zhu, Rui Zhao, Hongsheng Li, Mathieu Salzmann <!-- (*Co-first Authors) -->
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">ICCV, 2021</font>
													[<a href = "https://sailor-z.github.io/projects/CLNet" target="_blank">Project</a>]
													[<a href = "https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Progressive_Correspondence_Pruning_by_Consensus_Learning_ICCV_2021_paper.pdf" target="_blank">Paper</a>]
													[<a href = "https://github.com/sailor-z/CLNet" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/sailor-z/CLNet?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Online Pseudo Label Generation by Hierarchical Cluster Dynamics for Adaptive Person Re-identification
												</div>
												<div class="resume-degree-org text-muted">
													Yi Zheng, Shixiang Tang, Guolong Teng, <b>Yixiao Ge</b>, Kaijian Liu, Donglian Qi, Jing Qin, Dapeng Chen
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">ICCV, 2021</font>
														[<a href = "https://openaccess.thecvf.com/content/ICCV2021/papers/Zheng_Online_Pseudo_Label_Generation_by_Hierarchical_Cluster_Dynamics_for_Adaptive_ICCV_2021_paper.pdf" target="_blank">Paper</a>]
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification
												</div>
												<div class="resume-degree-org text-muted">
													Xiao Zhang*, <b>Yixiao Ge*</b>, Yu Qiao, Hongsheng Li
													<!-- (*Co-first Authors) -->
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">CVPR, 2021</font> [<a href = "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Refining_Pseudo_Labels_With_Clustering_Consensus_Over_Generations_for_Unsupervised_CVPR_2021_paper.pdf" target="_blank">Paper</a>]
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network
												</div>
												<div class="resume-degree-org text-muted">
													Rui Liu, <b>Yixiao Ge</b>, Ching Lam Choi, Xiaogang Wang, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">CVPR, 2021</font>
													[<a href = "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DivCo_Diverse_Conditional_Image_Synthesis_via_Contrastive_Generative_Adversarial_Network_CVPR_2021_paper.pdf" target="_blank">Paper</a>]
													[<a href = "https://github.com/ruiliu-ai/DivCo" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/ruiliu-ai/DivCo?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Mutual CRF-GNN Network for Few-shot Learning
												</div>
												<div class="resume-degree-org text-muted">
													Shixiang Tang, Dapeng Chen, Lei Bai, Kaijian Liu, <b>Yixiao Ge</b>, Wanli Ouyang
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">CVPR 2021 </font> [<a href = "https://openaccess.thecvf.com/content/CVPR2021/papers/Tang_Mutual_CRF-GNN_for_Few-Shot_Learning_CVPR_2021_paper.pdf" target="_blank">Paper</a>]
												</div>
											</li>
										</ul>
										<font color="#39AB56"><b>2020:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

											<li>
												<div class="resume-degree font-weight-bold">
													Self-paced Contrastive Learning with Hybrid Memory for Domain Adaptive Object Re-ID
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge</b>, Feng Zhu, Dapeng Chen, Rui Zhao, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">NeurIPS, 2020</font>
													[<a href = "./projects/spcl.html" target="_blank">Project</a>]
													[<a href = "https://proceedings.neurips.cc/paper/2020/file/821fa74b50ba3f7cba1e6c53e8fa6845-Paper.pdf" target="_blank">Paper</a>]
													[<a href = "https://github.com/yxgeee/SpCL" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/SpCL?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Self-supervising Fine-grained Region Similarities for Large-scale Image Localization
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge</b>, Haibo Wang, Feng Zhu, Rui Zhao, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">ECCV, 2020 <b>(Spotlight)</b></font>
													[<a href = "./projects/sfrs.html" target="_blank">Project</a>]
													[<a href = "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490358.pdf" target="_blank">Paper</a>]
													[<a href = "https://github.com/yxgeee/OpenIBL" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/OpenIBL?style=social">
												</div>
											</li>

											<li>
												<div class="resume-degree font-weight-bold">
													Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge</b>, Dapeng Chen, Hongsheng Li
												</div>
												<div class="resume-degree-org text-muted">
														<font color="#39AB56">ICLR, 2020</font>
													[<a href = "./projects/mmt.html" target="_blank">Project</a>]
													[<a href = "https://openreview.net/pdf?id=rJlnOhVYPS" target="_blank">Paper</a>]
													[<a href = "https://github.com/yxgeee/MMT" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/MMT?style=social">
												</div>
											</li>
										</ul>

										<font color="#39AB56"><b>Before 2020:</b></font>
										<ul class="resume-list" style="list-style: outside;" >

											<li>
												<div class="resume-degree font-weight-bold">
													FD-GAN: Pose-guided Feature Distilling GAN for Robust Person Re-identification
												</div>
												<div class="resume-degree-org text-muted">
													<b>Yixiao Ge*</b>, Zhuowan Li*, Haiyu Zhao, Guojun Yin, Shuai Yi, Xiaogang Wang, Hongsheng Li
													<!-- (*Co-first Authors) -->
												</div>
												<div class="resume-degree-org text-muted">
													<font color="#39AB56">NeurIPS, 2018</font>
													[<a href = "./projects/fdgan.html" target="_blank">Project</a>]
													[<a href = "http://papers.nips.cc/paper/7398-fd-gan-pose-guided-feature-distilling-gan-for-robust-person-re-identification.pdf" target="_blank">Paper</a>]
													[<a href = "https://github.com/yxgeee/FD-GAN" target="_blank">Code</a>]
													<img alt="GitHub stars" style="vertical-align:middle" src="https://img.shields.io/github/stars/yxgeee/FD-GAN?style=social">
												</div>
											</li>

										</ul>
									</div>
								</div><!--//item-->



							</section><!--//project-section-->
						</div><!--//resume-main-->
						<aside class="resume-aside col-12 col-lg-4 col-xl-3 px-lg-4 pb-lg-4">
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Education</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[2018-2021] Ph.D.,</div>
												<div class="resume-degree-org text-muted"><b>MMLab, The Chinese University of Hong Kong</b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[2013-2017] B.Eng.,</div>
												<div class="resume-degree-org text-muted"><b>Huazhong University of Science and Technology</b></div>
											</li>
										</ul>
									</section><!--//education-section-->
									<section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Experience</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[2021-present]</div>
												<div class="resume-degree font-weight-bold">Senior Researcher,</div>
												<div class="resume-degree-org text-muted"><b>Tencent</b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[2019-2020]</div>
												<div class="resume-degree font-weight-bold">Research Intern,</div>
												<div class="resume-degree-org text-muted"><b>SenseTime Research</b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[2017-2018]</div>
												<div class="resume-degree font-weight-bold">Research Assistant,</div>
												<div class="resume-degree-org text-muted"><b>MMLab, The Chinese University of Hong Kong</b></div>
											</li>
										</ul>
									</section><!--//education-section-->

									<!-- <section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Awards</h3>
										<ul class="list-unstyled resume-awards-list">
											<li class="mb-3">
												<div class="font-weight-bold">Future Star, SenseTime Group Limited. 2020</div>
											</li>
											<li class="mb-3">
												<div class="font-weight-bold">Outstanding PhD Thesis, CSIG</div>
											</li>
											<li class="mb-3">
												<div class="font-weight-bold">Wen-Tsun Wu Award, 2019</div>
											</li>
										</ul>
									</section> --><!--//education-section-->
									<section class="skills-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Reviewers</h3>
										<ul class="list-unstyled resume-lang-list">
											<ul class="list-unstyled pb-2">
												(Top-tier conferences)
												<li> <b>NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, AAAI</b> </li>
												<!-- <li> <b>NeurIPS</b> 2020, 2021, 2022</li>
												<li> <b>ICLR</b> 2021, 2022, 2023</li>
												<li> <b>ICML</b> 2021, 2022</li>
												<li><b>CVPR</b> 2021, 2022</li>
												<li><b>ICCV</b> 2021</li>
												<li><b>ECCV</b> 2022</li> -->
												<br>
												(Top-tier journals)
												<li> <b>IEEE TPAMI, IJCV, IEEE TIP, IEEE TCSVT, IEEE TMM, Neurocomputing</b></li>
											</ul>
										</ul>
									</section><!--//certificates-section-->


									<!-- <section class="education-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Invited Talks</h3>
										<ul class="list-unstyled resume-education-list">
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Jul 2022]</div>
												<div class="resume-degree-org text-muted"><b>"Video-language Pre-training and Representation Learning" at TAIC. <a href="https://mp.weixin.qq.com/s/2DMVFzKhjrhp9bf0tP7CIQ" target="_blank">[Poster]</a></b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Apr 2022]</div>
												<div class="resume-degree-org text-muted"><b>"Representation Learning at ARC Lab" at ICLR. <a href="https://iclr.cc/ExpoConferences/2022/Sponsorpage?id=155" target="_blank">[Web]</a></b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Dec 2020]</div>
												<div class="resume-degree-org text-muted"><b>"Analysis and Development of OpenUnReID Codebase" at ZhiDX (智东西). <a href="https://appoSCMf8kb5033.h5.xeknow.com/st/9k0kMekYC" target="_blank">[Video]</a></b></div>
											</li>
											<li class="mb-3">
												<div class="resume-degree font-weight-bold">[Nov 2020]</div>
												<div class="resume-degree-org text-muted"><b>"Unsupervised and Domain Adaptive Object Re-identification" at TechBeat (将门). <a href="https://www.techbeat.net/talk-info?id=456" target="_blank">[Video]</a></b></div>
											</li>

										</ul>
									</section> -->

									<section class="skills-section py-3">
										<h3 class="text-uppercase resume-section-heading mb-4">Collaborators</h3>
										<ul class="list-unstyled resume-lang-list">
											<ul class="list-unstyled pb-2">
												<li> <a href = "https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=en" target="_blank">Ying Shan</a></li>
												<li> <a href = "https://geyuying.github.io/" target="_blank">Yuying Ge</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=6xtzo4AAAAAJ" target="_blank">Kun Yi</a></li>
												<li> <a href = "http://linsong.info/" target="_blank">Lin Song</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=5fU_DtEAAAAJ" target="_blank">Chen Li</a></li>
												<li> <a href = "https://dblp.org/pid/179/2341.html" target="_blank">Yukang Gan</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=z4Nt3AQAAAAJ" target="_blank">Shupeng Su</a></li>
												<li> <a href = "https://dingxiaohan.xyz/" target="_blank">Xiaohan Ding</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=6FsgWBMAAAAJ" target="_blank">Zhan Tong</a></li>
												<li> <a href = "" target="_blank">Sijie Zhao</a></li>
												<li> <a href = "http://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Hongsheng Li</a></li>
												<li> <a href = "http://www.ee.cuhk.edu.hk/~xgwang/" target="_blank">Xiaogang Wang</a></li>
												<li> <a href = "http://zhaorui.xyz/" target="_blank">Rui Zhao</a></li>
												<li> <a href = "https://scholar.google.com/citations?user=-Wpd7FcAAAAJ&hl=en" target="_blank">Dapeng Chen</a></li>
												<li> <a href = "https://zhufengx.github.io/" target="_blank">Feng Zhu</a></li>
											</ul>
										</ul>
									</section>

							<!-- <script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=59b2dz2jgmo&amp;m=2&amp;c=007eff&amp;cr1=00ff6c&amp;sx=0" async="async"></script> -->
							<!-- <div style="width: 50%;">
        					<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=l25fbN5OAQusW9PW4IQZ6SVRyZFmlfUhwNbkjV8LeBc&co=333333&cmo=3acc3a&cmn=ff5353&ct=e7e7e7'></script>
        					<script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=l25fbN5OAQusW9PW4IQZ6SVRyZFmlfUhwNbkjV8LeBc"></script>
        					</div> -->
        					<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=220&t=tt&d=l25fbN5OAQusW9PW4IQZ6SVRyZFmlfUhwNbkjV8LeBc&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353"></script>

								</aside><!--//resume-aside-->
							</div><!--//row-->
						</div><!--//resume-body-->

					</article>

				</div><!--//container-->

				<!-- <footer class="footer text-center py-4">
					&lt;!&ndash;/* This template is free as long as you keep the footer attribution link. If you'd like to use the template without the attribution link, you can buy the commercial license via our website: themes.3rdwavemedia.com Thank you for your support. :) */&ndash;&gt;
					<small class="copyright text-muted">Designed with <i class="fas fa-heart"></i> by <a class="theme-link" href="http://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
				</footer> -->

			</div><!--//main-wrapper-->


</body>
</html>
